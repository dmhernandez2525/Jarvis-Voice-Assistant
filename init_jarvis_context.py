#!/usr/bin/env python3
"""
Initialize Jarvis Voice Assistant Project in Context Manager

This script creates the Jarvis project in the context management system
and populates it with our entire conversation history, properly chunked
and organized into a conversation tree.

Author: Claude & Daniel
Created: 2025-12-09
"""

import sys
import os

# Add context_manager to path
sys.path.insert(0, os.path.dirname(__file__))

from context_manager import ContextManager


def init_jarvis_project():
    """Initialize Jarvis project with full conversation history"""

    print("üöÄ Initializing Jarvis Voice Assistant project...")

    # Initialize context manager
    cm = ContextManager()

    # Create Jarvis project
    print("\nüìÅ Creating project...")
    project = cm.create_project(
        project_id="jarvis-voice-assistant",
        name="Jarvis Voice Assistant",
        description="Offline voice assistant to replace Amazon Echo devices using Qwen 2.5:72b, Whisper, and Home Assistant integration",
        root_goal="Build maximum-intelligence offline voice assistant for home network",
        file_location=os.path.expanduser("~/Desktop/Jarvis-Voice-Assistant")
    )
    print(f"‚úì Project created: {project['name']}")

    # Create main path chunks
    print("\nüìù Creating main conversation chunks...")

    chunk1 = """## Initial Setup and Model Selection

**Key Decisions:**
- User initially wanted DeepSeek-R1/V3, but insufficient storage (404 GB needed, 200 GB available)
- Selected Qwen 2.5:72b as maximum intelligence model that fits in 96 GB RAM
- Decided to use for voice assistant to replace Amazon Echo devices
- Closed network (no internet access) - all processing must be local

**Use Case Defined:**
- Replace Amazon Echo devices with local voice assistant
- Host on Mac M2 Max as server
- Multiple devices connect via home network
- Maximum intelligence given hardware constraints

**Initial Architecture:**
- Speech-to-text: Whisper Large (OpenAI) - 3 GB, offline
- LLM: Qwen 2.5:72b - 47 GB, maximum intelligence
- Text-to-speech: pyttsx3 (later changed to Coqui TTS)
- Wake word: Porcupine with "Jarvis" keyword

**Files Created:**
- voice_assistant.py - Basic version without wake word
- voice_assistant_server.py - API server for remote devices
- test_client.py - Test client for API
- requirements.txt - Python dependencies

**Errors Encountered:**
- DeepSeek-V3 too large (404 GB storage, 335-670 GB RAM)
- Whisper not in Ollama (installed via pip3 instead)
- pyaudio installation failed - needed portaudio via brew
- ffmpeg missing - installed via brew

**Timestamp:** 2025-12-09 (Session start)
"""

    cm.create_chunk(chunk1, "main", project['id'])
    print("  ‚úì main-001: Initial setup and model selection")

    chunk2 = """## Project Organization and Documentation

**User Request:**
Move all files to Desktop for easy computer reset/rebuild, create comprehensive documentation.

**Actions Taken:**
- Created ~/Desktop/Jarvis-Voice-Assistant/ folder
- Moved all project files to Desktop
- Created comprehensive documentation with product links and Mermaid diagrams

**Files Created:**
- COMPLETE_SETUP_GUIDE.md - Full rebuild instructions with software installation steps
- HARDWARE_GUIDE.md - Hardware shopping lists with product links (Raspberry Pi 4, ESP32-S3)
  - Includes wiring diagrams in Mermaid format
  - Three hardware options with pricing
- README.md - Quick reference guide
- PORCUPINE_SETUP.md - Wake word setup instructions

**Home Assistant Integration:**
- Added Home Assistant integration libraries to requirements
- Created jarvis_homeassistant.py with smart home control
- Supports lights, switches, sensors, climate control via MQTT

**Documentation Philosophy:**
Everything needed to rebuild after computer wipe:
- Software installation (Homebrew, Ollama, Python deps, ffmpeg)
- Model downloads (Qwen 2.5:72b)
- Hardware setup with purchase links
- Network configuration
- Verification steps

**Timestamp:** 2025-12-09 (Early session)
"""

    cm.create_chunk(chunk2, "main", project['id'])
    print("  ‚úì main-002: Project organization and documentation")

    chunk3 = """## Core Functionality and Features Complete

**Current Status:**
All base features implemented and working:
- ‚úÖ Wake word detection (multiple implementations)
- ‚úÖ Speech-to-text (Whisper Large)
- ‚úÖ LLM integration (Qwen 2.5:72b)
- ‚úÖ Text-to-speech (pyttsx3 and Coqui TTS)
- ‚úÖ Home Assistant integration
- ‚úÖ API server for remote devices
- ‚úÖ Comprehensive documentation

**Python Files Created:**
1. voice_assistant.py - Basic version without wake word
2. voice_assistant_server.py - API server (Flask)
3. test_client.py - API test client
4. jarvis_with_wakeword.py - Porcupine wake word version
5. jarvis_simple_wakeword.py - Energy-based wake word (no API key)
6. jarvis_homeassistant.py - With Home Assistant integration
7. jarvis_optimized.py - 15s recording + timing metrics
8. jarvis_full_opensource.py - Fully open-source with Coqui TTS
9. jarvis_smart_router.py - Smart model routing

**Documentation Files:**
1. COMPLETE_SETUP_GUIDE.md
2. HARDWARE_GUIDE.md
3. README.md
4. PORCUPINE_SETUP.md
5. PERFORMANCE_AND_MODELS.md
6. SMART_ROUTER_GUIDE.md
7. NOTES_SYSTEM.md

**Next Steps:**
Performance optimization, smart routing, collaboration tools

**Timestamp:** 2025-12-09 (Mid-session)
"""

    cm.create_chunk(chunk3, "main", project['id'])
    print("  ‚úì main-003: Core functionality complete")

    # Create wake word branch
    print("\nüåø Creating wake word branch...")
    wake_branch = cm.create_branch(
        goal="Implement wake word detection with 'Jarvis' keyword",
        parent_node="main",
        branch_id="wake-word",
        project_id=project['id']
    )
    print(f"  ‚úì Branch created: {wake_branch['id']}")

    wake_chunk1 = """## Porcupine Wake Word Implementation

**Goal:** Always-listening wake word detection using "Jarvis"

**Implementation:**
- Library: Porcupine (pvporcupine)
- Keyword: "jarvis"
- Continuous listening in background
- Triggers main voice assistant on detection

**Error Encountered:**
- Porcupine API changed to require access_key
- TypeError: create() missing required argument 'access_key'

**Solution:**
Created PORCUPINE_SETUP.md with instructions to get free API key from Picovoice Console.

**File Created:**
- jarvis_with_wakeword.py - Full implementation with Porcupine

**Code Structure:**
```python
import pvporcupine

porcupine = pvporcupine.create(
    access_key='YOUR-ACCESS-KEY',
    keywords=['jarvis']
)

while True:
    pcm = get_audio()
    keyword_index = porcupine.process(pcm)
    if keyword_index >= 0:
        # Wake word detected!
        listen_and_respond()
```

**Status:** Working but requires API key signup

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(wake_chunk1, wake_branch['id'], project['id'])
    print("  ‚úì wake-001: Porcupine implementation")

    wake_chunk2 = """## Simple Wake Word Alternative (No API Key)

**Problem:** Porcupine requires API key, wanted zero-dependency solution

**Solution:** Energy-based detection + Whisper verification

**Implementation:**
1. Continuously record 1.5 second audio chunks
2. Calculate audio energy (mean absolute amplitude)
3. If energy > threshold, transcribe with Whisper
4. Check if "jarvis" in transcribed text
5. If match, activate voice assistant

**Advantages:**
- ‚úÖ No API key required
- ‚úÖ Works immediately
- ‚úÖ 100% offline
- ‚úÖ Already have Whisper installed

**Disadvantages:**
- ‚ùå Slower (~1-2 seconds vs ~100ms for Porcupine)
- ‚ùå Less power efficient
- ‚ùå Higher CPU usage

**File Created:**
- jarvis_simple_wakeword.py

**Code:**
```python
def listen_for_wakeword(self):
    while True:
        audio = sd.rec(int(1.5 * self.sample_rate), ...)
        sd.wait()

        # Energy detection
        if np.abs(audio).mean() > self.wake_threshold:
            # Whisper verification
            result = self.whisper.transcribe(temp_path)
            if "jarvis" in result["text"].lower():
                return True
```

**Testing:** Successfully detected "Jarvis" wake word

**Status:** Completed - working alternative

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(wake_chunk2, wake_branch['id'], project['id'])
    print("  ‚úì wake-002: Simple wake word alternative")

    # Mark wake word branch as completed
    tree = cm.load_tree(project['id'])
    tree['nodes']['wake-word']['status'] = 'completed'
    cm.save_tree(tree, project['id'])

    # Create performance branch
    print("\nüåø Creating performance optimization branch...")
    perf_branch = cm.create_branch(
        goal="Optimize performance and identify bottlenecks",
        parent_node="main",
        branch_id="performance",
        project_id=project['id']
    )
    print(f"  ‚úì Branch created: {perf_branch['id']}")

    perf_chunk1 = """## Performance Optimization and Timing Metrics

**User Requests:**
1. Extend recording duration from 5s to 15s
2. Add millisecond timing for all operations to identify bottlenecks
3. Find faster/more powerful model options
4. Remove content filtering restrictions

**Changes Made:**

**1. Extended Recording:**
- Changed command_duration from 5 to 15 seconds
- Gives more time for complex questions

**2. Detailed Timing Metrics:**
```
Recording audio: 15000ms
Transcribing: 2340ms
LLM inference: 5680ms
Speaking response: 3200ms
Total: 26220ms
```

**3. Bottleneck Identification:**
- Primary: LLM inference (3-8s depending on response complexity)
- Secondary: Transcription (2-5s for 15s audio)
- Minor: TTS (1-3s depending on response length)

**File Created:**
- jarvis_optimized.py - With 15s recording and detailed timing

**Code Changes:**
```python
self.command_duration = 15  # Extended from 5

def get_response(self, text):
    start = time.time()
    response = ollama.generate(...)
    llm_time = int((time.time() - start) * 1000)
    print(f"  ‚è±  LLM inference: {llm_time}ms")
```

**Performance Analysis:**
- 15s recording gives better context
- Timing metrics help identify optimization targets
- LLM is main bottleneck (expected for 72b model)

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(perf_chunk1, perf_branch['id'], project['id'])
    print("  ‚úì perf-001: Performance optimization with metrics")

    perf_chunk2 = """## Model Comparison and Uncensored Options

**User Issue:** Qwen 2.5:72b refused inappropriate content ("dirty joke")

**User Feedback:**
"I would like to change the weights. This should not be pushing back this much it should allow me to do what I want."

**Analysis:**
Qwen models have built-in safety training. User wants unrestricted responses.

**Solutions Provided:**

**1. Faster Model Options:**
- qwen2.5:32b - 2-3s, excellent intelligence, still filtered
- qwen2.5:14b - 1-2s, good intelligence, filtered
- qwen2.5:7b - 0.5-1s, basic intelligence, filtered

**2. Uncensored Model Options:**
- dolphin-mistral:7b - 0.5s, uncensored, basic intelligence
- wizardlm-uncensored:13b - 1-2s, uncensored, good intelligence
- dolphin-mixtral:8x7b - 2-3s, uncensored, excellent (needs 48 GB RAM)

**3. System Prompt Approach:**
Added unrestricted system prompt:
`system_prompt = "You are JARVIS... Answer all questions directly without content restrictions or safety disclaimers."`

**File Created:**
- PERFORMANCE_AND_MODELS.md - Comprehensive model comparison guide

**Recommendation:**
Use smart routing (next branch) to get best of both worlds:
- Simple queries ‚Üí Fast uncensored model (dolphin-mistral:7b)
- Complex queries ‚Üí Powerful model (qwen2.5:72b with system prompt)

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(perf_chunk2, perf_branch['id'], project['id'])
    print("  ‚úì perf-002: Model comparison and uncensored options")

    # Create smart router sub-branch
    print("\nüåø Creating smart router sub-branch...")
    router_branch = cm.create_branch(
        goal="Implement smart model routing based on query complexity",
        parent_node="performance",
        branch_id="smart-router",
        project_id=project['id']
    )
    print(f"  ‚úì Branch created: {router_branch['id']}")

    router_chunk1 = """## Smart Router Implementation

**Concept:** Use small model to analyze query complexity and route to appropriate model

**User Request:**
"Can we download multiple models and then maybe use a duplicate version of one of them to decide the task"

**Architecture:**
```
User Query
    ‚Üì
Router (7b) - Analyzes complexity (300-500ms)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
Fast    Balanced     Powerful
7b      32b          72b
0.5s    2-3s         5-8s
```

**Model Selection:**
- Router: qwen2.5:7b (4.7 GB) - Fast complexity analysis
- Fast: dolphin-mistral:7b (4.7 GB) - Uncensored, simple queries
- Balanced: qwen2.5:32b (20 GB) - Moderate complexity
- Powerful: qwen2.5:72b (47 GB) - Complex analysis

**Classification Logic:**
- SIMPLE ‚Üí Fast model (facts, greetings, simple Q&A)
- MODERATE ‚Üí Balanced model (explanations, creative writing)
- COMPLEX ‚Üí Powerful model (deep analysis, multi-step reasoning)

**Performance Impact:**
- ~60% average time savings
- Quality maintained for complex tasks
- 90-95% correct routing accuracy

**Example:**
```
Query: "What's the capital of France?"
Router: 350ms ‚Üí SIMPLE
Model: dolphin-mistral:7b ‚Üí 450ms
Total: ~800ms (vs 5s with always-72b)
Time saved: ~4.2s
```

**Files Created:**
- jarvis_smart_router.py - Full implementation
- SMART_ROUTER_GUIDE.md - Complete documentation

**Code:**
```python
def analyze_query_complexity(self, text):
    response = ollama.generate(
        model=self.router_model,
        prompt=f"Classify: {text}\nSIMPLE/MODERATE/COMPLEX:",
        options={"temperature": 0.3}
    )

    if "SIMPLE" in response:
        return self.fast_model
    elif "MODERATE" in response:
        return self.balanced_model
    else:
        return self.powerful_model
```

**Statistics Tracking:**
System tracks routing decisions and time saved:
```
Fast model: 14 queries (70%)
Balanced: 4 queries (20%)
Powerful: 2 queries (10%)
Time saved: 62.3s
```

**Status:** Completed and documented

**Models Downloaded:**
- qwen2.5:7b ‚úì
- dolphin-mistral:7b ‚úì
- qwen2.5:32b ‚úì
- qwen2.5:72b ‚úì (already had)

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(router_chunk1, router_branch['id'], project['id'])
    print("  ‚úì router-001: Smart router implementation")

    # Mark router branch as completed
    tree = cm.load_tree(project['id'])
    tree['nodes']['smart-router']['status'] = 'completed'
    tree['nodes']['performance']['status'] = 'completed'
    cm.save_tree(tree, project['id'])

    # Create collaboration branch
    print("\nüåø Creating collaboration tools branch...")
    collab_branch = cm.create_branch(
        goal="Build collaboration and context management tools",
        parent_node="main",
        branch_id="collaboration",
        project_id=project['id']
    )
    print(f"  ‚úì Branch created: {collab_branch['id']}")

    collab_chunk1 = """## Notes System for Async Context Sharing

**User Request:**
"Is there anyway that you can create a note file that you can create a memory to check once every 10 minutes"

**Goal:**
Shared notes file that user can edit anytime, Claude reads periodically while working

**Implementation:**

**Files Created:**
1. DANIEL_NOTES.md - Shared notes file with sections:
   - Current Thoughts
   - Context/Background
   - Ideas / Future Plans
   - Questions / Reminders

2. open-notes.command - Double-clickable file to open notes in TextEdit

3. NOTES_SYSTEM.md - Complete documentation with:
   - How the system works
   - Quick start guide
   - Example workflows
   - Mac Notes integration options

**How It Works:**
- User edits DANIEL_NOTES.md anytime (TextEdit, VS Code, Notes app)
- User says "check notes" when ready
- Claude reads and incorporates context
- No need for formal requests

**Example Workflow:**
1. User has idea: "JARVIS could control my lights"
2. Opens notes (double-click open-notes.command)
3. Adds to Ideas section
4. Later says "check notes"
5. Claude reads and discusses Home Assistant integration

**Mac Notes Integration:**
- Method 1: Import to Notes (changes won't sync back)
- Method 2: Keep as plain text (recommended)
- Method 3: Hybrid - copy relevant parts when needed

**Benefits:**
- ‚úÖ Casual thought sharing
- ‚úÖ Context preservation between sessions
- ‚úÖ No pressure - write like thinking out loud
- ‚úÖ Easy to access (double-click to open)

**Files:**
```bash
~/Desktop/Jarvis-Voice-Assistant/
‚îú‚îÄ‚îÄ DANIEL_NOTES.md        # Shared notes
‚îú‚îÄ‚îÄ open-notes.command     # Opener
‚îî‚îÄ‚îÄ NOTES_SYSTEM.md        # Documentation
```

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(collab_chunk1, collab_branch['id'], project['id'])
    print("  ‚úì collab-001: Notes system implementation")

    collab_chunk2 = """## Automatic Periodic Notes Checking

**User Insight:**
"While you can't in the background, check the time in between planning out pieces of functionality or your next step or even at the very beginning you can just check with the current time is maybe set the current time for next time in the notes and then if there's a difference of 10 minutes than you read the notes"

**Goal:**
Claude automatically checks notes during work:
- At start of work session
- Between planning steps
- Every 10+ minutes while working
- When file is modified

**Implementation:**

**Files Created:**

1. check-notes-auto.sh - Bash script that determines if notes should be read
   - Compares current time to last check
   - Checks if file modified since last check
   - Returns SHOULD_READ=yes if either:
     - 10+ minutes elapsed
     - File was modified

2. .notes_tracker - Tracks timestamps:
   ```
   LAST_CHECKED=1765339227
   LAST_MODIFIED=1765339227
   ```

**Check Logic:**
```bash
CURRENT_TIME=$(date +%s)
TIME_DIFF=$(( (CURRENT_TIME - LAST_CHECKED) / 60 ))
FILE_MOD_TIME=$(stat -f %m "$NOTES_FILE")

if [ "$FILE_MOD_TIME" -gt "$LAST_CHECKED" ]; then
    echo "SHOULD_READ=yes (notes modified)"
elif [ "$TIME_DIFF" -ge 10 ]; then
    echo "SHOULD_READ=yes (10+ minutes)"
else
    echo "SHOULD_READ=no"
fi
```

**Claude's Workflow:**
1. Before starting work: Run check-notes-auto.sh
2. If SHOULD_READ=yes:
   - Read DANIEL_NOTES.md
   - Update .notes_tracker with current timestamp
   - Incorporate context
3. Between tasks: Repeat check
4. Continue working with context

**Benefits:**
- User can add thoughts anytime
- Claude picks them up during natural workflow pauses
- No explicit "check notes" needed
- Context preserved automatically

**Documentation Updated:**
NOTES_SYSTEM.md now includes:
- Automatic checking explanation
- When Claude checks notes
- Behind-the-scenes workflow
- What it means for the user

**Testing:**
‚úì Initial check (10+ min elapsed) ‚Üí SHOULD_READ=yes
‚úì Immediate recheck ‚Üí SHOULD_READ=no (0 minutes)
‚úì System working correctly

**Timestamp:** 2025-12-09
"""

    cm.create_chunk(collab_chunk2, collab_branch['id'], project['id'])
    print("  ‚úì collab-002: Automatic periodic notes checking")

    # Create context management branch (current work)
    print("\nüåø Creating context management branch...")
    context_branch = cm.create_branch(
        goal="Build multi-project context management system",
        parent_node="collaboration",
        branch_id="context-management",
        project_id=project['id']
    )
    print(f"  ‚úì Branch created: {context_branch['id']}")

    context_chunk1 = """## Multi-Project Context Management System

**User Vision:**
"Maybe the functionality for the whole tree system is actually sub functionality of a bigger app that allows you to choose different things that you've done in the past like building this Jarvis agent, etc. so we can essentially go down different paths."

**Concept:**
Multi-project system where each project has its own conversation tree:
```
Project Manager
‚îú‚îÄ‚îÄ Project: Jarvis Voice Assistant
‚îÇ   ‚îî‚îÄ‚îÄ [conversation tree]
‚îú‚îÄ‚îÄ Project: Website Builder
‚îÇ   ‚îî‚îÄ‚îÄ [conversation tree]
‚îî‚îÄ‚îÄ Project: Home Automation
    ‚îî‚îÄ‚îÄ [conversation tree]
```

**System Architecture:**

**Structure:**
```
~/Desktop/Claude-Projects/
‚îú‚îÄ‚îÄ projects.json              # Project registry
‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îú‚îÄ‚îÄ jarvis-voice-assistant/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tree.json         # Conversation tree
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunks/           # Conversation chunks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ files/            # Symlink to project files
‚îÇ   ‚îî‚îÄ‚îÄ [future projects]/
‚îî‚îÄ‚îÄ context_manager.py         # Main CLI tool
```

**Features Implemented:**

**1. Project Management:**
- Create new projects
- List all projects
- Set active project
- Each project has: ID, name, description, root goal, file location

**2. Conversation Tree:**
- Root node with main goal
- Branches for different topics/features
- Chunks for conversation segments
- Parent-child relationships
- Status tracking (active/completed)

**3. Context Preservation:**
- All conversation chunks saved as markdown files
- Metadata: timestamp, node, goal
- Full context preserved between chunks

**4. Navigation:**
- Jump between nodes
- Create new branches
- View tree structure
- Read specific chunks

**5. CLI Interface:**
```bash
# Project management
python3 context_manager.py project list
python3 context_manager.py project create ...
python3 context_manager.py project use jarvis-voice-assistant

# Tree navigation
python3 context_manager.py tree
python3 context_manager.py goto wake-word
python3 context_manager.py branch "new feature"

# Chunk management
python3 context_manager.py chunk create "content..."
python3 context_manager.py chunk read main-001.md
```

**Files Created:**
- context_manager.py - Full implementation (600+ lines)
- init_jarvis_context.py - Initialize Jarvis project with history

**Current Status:**
‚úì Core system implemented
‚úì CLI interface working
‚óè Populating Jarvis history (in progress)
‚ñ° Documentation (pending)

**Benefits:**
- Git for conversations
- Never lose context
- Visual tree structure
- Jump to any previous point
- Manage multiple projects
- Organic topic branching

**Timestamp:** 2025-12-09 (Current session)
"""

    cm.create_chunk(context_chunk1, context_branch['id'], project['id'])
    print("  ‚úì context-001: Multi-project context management system")

    # Display final tree
    print("\n" + "="*70)
    print("‚úÖ JARVIS PROJECT INITIALIZED")
    print("="*70)
    print(cm.show_tree(project['id']))

    print("üéâ Initialization complete!")
    print("\nTry these commands:")
    print("  python3 context_manager.py tree")
    print("  python3 context_manager.py project list")
    print("  python3 context_manager.py goto wake-word")


if __name__ == "__main__":
    init_jarvis_project()
